<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="distribution">
  <title>Distribution and Skew</title>
    <shortdesc>Greenplum Database relies on even distribution of data across segments.</shortdesc>
    <body>
      <p>In an MPP shared nothing environment, overall response time for
        a query is measured by the completion time for all segments. The system is only as fast as
        the slowest segment. If the data is skewed, segments with more data will take more time to
        complete, so every segment must have an approximately equal number of rows and perform
        approximately the same amount of processing. Poor performance and out of memory conditions
        may result if one segment has significantly more data to process than other segments. </p>
      <p>Optimal distributions are critical when joining large tables together. To perform a join,
        matching rows must be located together on the same segment. If data is not distributed on
        the same join column, the rows needed from one of the tables are dynamically redistributed
        to the other segments. In some cases a broadcast motion, in which each segment sends its
        individual rows to all other segments, is performed rather than a redistribution motion,
        where each segment rehashes the data and sends the rows to the appropriate segments
        according to the hash key. </p>
    </body>
    <topic id="topic1">
      <title>Local (Co-located) Joins</title>
        <body>
        <p>Using a hash distribution that evenly distributes table rows across all segments and
          results in local joins can provide substantial performance gains. When joined rows are on
          the same segment, much of the processing can be accomplished within the segment instance.
          These are called <i>local</i> or <i>co-located</i> joins. Local joins minimize data
          movement; each segment operates independently of the other segments, without network
          traffic or communications between segments. </p>
        <p>To achieve local joins for large tables commonly joined together, distribute the tables
          on the same column. Local joins require that both sides of a join be distributed on the
          same columns (and in the same order) <i>and</i> that all columns in the distribution
          clause are used when joining tables. The distribution columns must also be the same data
          typeâ€”although some values with different data types may appear to have the same
          representation, they are stored differently and hash to different values, so they are
          stored on different segments.</p>
    </body>
      </topic>
      <topic id="topic2">
        <title>Data Skew</title>
    <body>
        <p>Data skew may be caused by uneven data distribution due to the wrong choice of distribution
          keys or single tuple table insert or copy operations. Present at the table level, data
          skew, is often the root cause of poor query performance and out of memory conditions.
          Skewed data affects scan (read) performance, but it also affects all other query execution
          operations, for instance, joins and group by operations. </p>
        <p>It is very important to <i>validate</i> distributions to <i>ensure</i> that data is
          evenly distributed after the initial load. It is equally important to <i>continue</i> to
          validate distributions after incremental loads. </p>
        <p>The following query shows the number of rows per segment as well as the variance from the
          minimum and maximum numbers of rows:</p>
        <codeblock>SELECT 'Example Table' AS "Table Name", 
    max(c) AS "Max Seg Rows", min(c) AS "Min Seg Rows", 
    (max(c)-min(c))*100.0/max(c) AS "Percentage Difference Between Max &amp; Min" 
FROM (SELECT count(*) c, gp_segment_id FROM facts GROUP BY 2) AS a;</codeblock>
        <p>The <codeph>gp_toolkit</codeph> schema has two views that you can use to check for
            skew.<ul id="ul_cg4_1vp_y4">
            <li>The <codeph>gp_toolkit.gp_skew_coefficients</codeph> view shows data distribution
              skew by calculating the coefficient of variation (CV) for the data stored on each
              segment. The <codeph>skccoeff</codeph>  column shows the coefficient of variation
              (CV), which is calculated as the standard deviation divided by the average. It takes
              into account both the average and variability around the average of a data series. The
              lower the value, the better. Higher values indicate greater data skew.</li>
            <li>The <codeph>gp_toolkit.gp_skew_idle_fractions</codeph> view shows data distribution
              skew by calculating the percentage of the system that is idle during a table scan,
              which is an indicator of computational skew. The <codeph>siffraction</codeph> column
              shows the percentage of the system that is idle during a table scan. This is an
              indicator of uneven data distribution or query processing skew. For example, a value
              of 0.1 indicates  10% skew, a value of 0.5 indicates 50% skew, and so on. Tables that
              have more than10% skew should have their distribution policies evaluated.</li>
          </ul></p>
      <section id="section_unk_dpf_kgb">
        <title>Considerations for Replicated Tables</title>
        <p>When you create a replicated table (with the <codeph>CREATE TABLE</codeph> clause
            <codeph>DISTRIBUTED REPLICATED</codeph>), Greenplum Database distributes every table row
          to every segment instance. Replicated table data is evenly distributed because every
          segment has the same rows. A query that uses the <codeph>gp_segment_id</codeph> system
          column on a replicated table to verify evenly distributed data, will fail because
          Greenplum Database does not allow queries to reference replicated tables' system
          columns.</p>
      </section>
        </body>
      </topic>
      <topic id="topic3">
        <title>Processing Skew</title>
    <body>
        <p>Processing skew results when a disproportionate amount of data flows to, and is processed
          by, one or a few segments. It is often the culprit behind Greenplum Database performance
          and stability issues. It can happen with operations such join, sort, aggregation, and
          various OLAP operations. Processing skew happens in flight while a query is running and
          is not as easy to detect as data skew.</p>
        <p>If single segments are failing, that is, not all segments on a host, it may be a
          processing skew issue. Identifying processing skew is currently a manual process. First
          look for spill files. If there is skew, but not enough to cause spill, it will not become
          a performance issue. If you determine skew exists, then find the query responsible for the
          skew.</p>
        <p>The remedy for processing skew in almost all cases is to rewrite the query. Creating
          temporary tables can eliminate skew. Temporary tables can be randomly distributed to force
          a two-stage aggregation. </p>
    </body>
      </topic>
</topic>
